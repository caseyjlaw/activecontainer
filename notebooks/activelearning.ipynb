{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "# realbogus for realfast\n",
    "\n",
    "## Machine Learning for VLA fast transient classification (using elastic search)\n",
    "\n",
    "### By Umaa Rebbapragada and Casey Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "import os.path\n",
    "import numpy as np\n",
    "import activegit, rflearn\n",
    "from rtpipe.parsecands import read_candidates\n",
    "import glob, logging\n",
    "from IPython.display import Image, display\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "verbose = 0\n",
    "random_seed = 1132014\n",
    "np.random.seed(seed=random_seed)\n",
    "\n",
    "def serveimage(imagename, baseurl='http://www.aoc.nrao.edu/~claw/plots/', width=700):\n",
    "    display(Image(url=os.path.join(baseurl, imagename), width=width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "### Initialize activegit repo with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "outputs": [],
   "source": [
    "agdir = os.path.join(os.environ['HOME'], 'code', 'realfast_al')\n",
    "ag = activegit.ActiveGit(agdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "### Read new (unlabeled) candidates and define (loc, prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "urth": {
     "dashboard": {}
    }
   },
   "outputs": [],
   "source": [
    "datalist = rflearn.elastic.indextodatalist(unlabeled=True)\n",
    "obslist, loc, prop = rflearn.elastic.restorecands(datalist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "source": [
    "### Active learning loop\n",
    "\n",
    "#### Take least certain predictions and ask expert to classify. Result is then fed back in to classifier to improve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "outputs": [],
   "source": [
    "# set up train, test and unlabeled pools\n",
    "clf = ag.classifier\n",
    "train_pool, train_targets = ag.training_data\n",
    "test_pool, test_targets = ag.testing_data\n",
    "unlabeled_pool_stat = rflearn.features.stat_features(prop)\n",
    "\n",
    "# set up batches\n",
    "nunlabeled = len(obslist)\n",
    "cands_unlabeled_pool = np.array(range(nunlabeled))\n",
    "subset_threshold = 75\n",
    "subset_perc = 0.666\n",
    "n_jobs = 1\n",
    "batch_size = 10\n",
    "bi = 0 # batch index\n",
    "nbatches = nunlabeled/batch_size\n",
    "\n",
    "logger.info(\"Train pool size: {0}\".format(len(train_pool)))\n",
    "logger.info(\"Test pool size: {0}\".format(len(test_pool)))\n",
    "logger.info(\"Unlabeled pool size: {0}\".format(nunlabeled))\n",
    "logger.info(\"Batch size: {0}\".format(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "urth": {
     "dashboard": {
      "layout": {
       "col": 0,
       "height": 29,
       "row": 0,
       "width": 5
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# START ACTIVE LEARNING LOOP\n",
    "\n",
    "while (nunlabeled > 0): # while still examples in unlabeled pool\n",
    "    \n",
    "    # choose a subset of the unlabeled pool to classify\n",
    "    subset_size = int(np.floor(subset_perc * nunlabeled)) if (nunlabeled > subset_threshold) else nunlabeled\n",
    "    cands_rand_subset = np.random.choice(cands_unlabeled_pool, subset_size, replace=False)\n",
    "    subset_pool = unlabeled_pool_stat[cands_rand_subset,:]\n",
    "\n",
    "    if clf:\n",
    "        # get performance stats for classifier on validation set\n",
    "        test_preds = clf.predict(test_pool)    \n",
    "        acc, fpr, fnr = rflearn.features.calc_acc_fpr_fnr(test_targets, test_preds)\n",
    "        logger.info(\"BATCH {0} (acc, fpr, fnr): ({1}, {2}, {3})\\n\".format(bi, acc, fpr, fnr))\n",
    "        \n",
    "        # classify that subset\n",
    "        subset_pool_probs = clf.predict_proba(subset_pool) \n",
    "    \n",
    "        # choose the most uncertain bunch to present to the user\n",
    "        batch_subset_indices = (np.argsort(abs(subset_pool_probs[:,0] - subset_pool_probs[:,1])))[0:batch_size]\n",
    "        batch_subset_probs = subset_pool_probs[batch_subset_indices,:]\n",
    "    \n",
    "        # ... finds the corresponding cands from the unlabeled pools\n",
    "        batch_cand_indices = cands_rand_subset[batch_subset_indices]\n",
    "    else:\n",
    "        # need to initialize train/test/clf with first pass\n",
    "        batch_cand_indices = cands_rand_subset[0:batch_size]\n",
    "        \n",
    "    # present cand_indices to the user\n",
    "    batch_cand_targets = []\n",
    "    modified_data = []\n",
    "    # move those examples into the training pool, remove them from the unlabeled pool\n",
    "    for ci in range(batch_size):\n",
    "        candi = batch_cand_indices[ci]\n",
    "        logger.info('SNR = {0}'.format(unlabeled_pool_stat[candi,0]))\n",
    "        if clf:\n",
    "            logger.info(\"RDF Probs=({0},{1})\".format(batch_subset_probs[ci,0], batch_subset_probs[ci,1]) )\n",
    "        serveimage(datalist[candi]['candidate_png'])\n",
    "        \n",
    "        while 1:\n",
    "            label = int(raw_input(\"LABEL: Is this real? (0,1) \"))\n",
    "            if label not in [0,1]:\n",
    "                logger.warn(\"Please enter in 0 or 1 only\")\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        batch_cand_targets.append(label)\n",
    "        datalist[candi]['labeled'] = 1\n",
    "        modified_data.append(datalist[candi])\n",
    "\n",
    "    # update elastic search index to show that a batch has been classified\n",
    "#    rflearn.elastic.pushdata(modified_data)\n",
    "    \n",
    "    # augment train_pool, train_targets\n",
    "    if len(train_pool) and len(test_pool):\n",
    "        train_pool = np.vstack( (train_pool, unlabeled_pool_stat[batch_cand_indices,:]) )\n",
    "        train_targets = np.concatenate( (train_targets, batch_cand_targets) )\n",
    "    else:\n",
    "        # first time through. split sample to train/test\n",
    "        train_pool = unlabeled_pool_stat[batch_cand_indices[:batch_size/2],:]\n",
    "        train_targets = batch_cand_targets[:batch_size/2]\n",
    "        test_pool = unlabeled_pool_stat[batch_cand_indices[batch_size/2:],:]\n",
    "        test_targets = batch_cand_targets[batch_size/2:]\n",
    "\n",
    "    cands_unlabeled_pool = np.delete(cands_unlabeled_pool, batch_cand_indices, axis=0)\n",
    "    nunlabeled = cands_unlabeled_pool.shape[0]\n",
    "    bi += 1\n",
    "\n",
    "    logger.info(\"Train pool size: {0}\".format(len(train_pool)))\n",
    "    logger.info(\"Test pool size: {0}\".format(len(test_pool)))\n",
    "    logger.info(\"Unlabeled pool size: {0}\".format(nunlabeled))\n",
    "    logger.info(\"Batch size: {0}\".format(batch_size))\n",
    "    \n",
    "    # re-train \n",
    "    logger.info(\"Retraining classifier...\")\n",
    "    clf = rflearn.sklearn_utils.train_random_forest(train_pool, train_targets, n_jobs=n_jobs, \n",
    "                                                    verbose=verbose, n_estimators=300)\n",
    "\n",
    "    # ask to continue\n",
    "    value = raw_input(\"Continue? (y,n): \")\n",
    "    if value ==  'n':\n",
    "        logger.info(\"Saving train, targets, and classifier to next version name...\")\n",
    "        try:\n",
    "            lastvers = max([int(version.lstrip('stat')) for version in ag.versions if 'stat' in version])\n",
    "        except ValueError:\n",
    "            lastvers = 0\n",
    "        finally:\n",
    "            versn = lastvers + 1\n",
    "        ag.write_testing_data([tuple(tr) for tr in test_pool], test_targets)\n",
    "        ag.write_training_data([tuple(tr) for tr in train_pool], train_targets)\n",
    "        ag.write_classifier(clf)\n",
    "        ag.commit_version('stat{0}'.format(versn))\n",
    "        break\n",
    "    else:\n",
    "        logger.info('Continuing training...')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "urth": {
     "dashboard": {
      "hidden": true
     }
    }
   },
   "outputs": [],
   "source": [
    "for version in ag.versions:\n",
    "    ag.set_version(version)\n",
    "    clf = ag.classifier\n",
    "    test_pool, test_targets = ag.testing_data\n",
    "    if clf:\n",
    "        test_preds = clf.predict(test_pool)\n",
    "        acc, fpr, fnr = rflearn.features.calc_acc_fpr_fnr(test_targets, test_preds)\n",
    "        logger.info('Version {0}, {1} test cands (acc, fpr, fnr): ({1}, {2}, {3})'\n",
    "                    .format(version, len(test_pool), acc, fpr, fnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "urth": {
   "dashboard": {
    "cellMargin": 10,
    "defaultCellHeight": 20,
    "layoutStrategy": "packed",
    "maxColumns": 12
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
