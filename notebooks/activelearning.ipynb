{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# realbogus for realfast\n",
    "\n",
    "## Machine Learning for VLA fast transient classification (using elastic search)\n",
    "\n",
    "### By Umaa Rebbapragada and Casey Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "import os.path\n",
    "import numpy as np\n",
    "import activegit, rflearn\n",
    "from rtpipe.parsecands import read_candidates\n",
    "import glob, logging\n",
    "from IPython.display import Image, display\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verbose = 0\n",
    "random_seed = 1132014\n",
    "np.random.seed(seed=random_seed)\n",
    "\n",
    "def serveimage(imagename, baseurl='http://www.aoc.nrao.edu/~claw/plots/', width=700):\n",
    "    display(Image(url=os.path.join(baseurl, imagename), width=width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize activegit repo with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agdir = os.path.join(os.environ['HOME'], 'code', 'alnotebook')\n",
    "if not os.path.exists(agdir):\n",
    "    agdir = raw_input(\"Specify activegit repo:\")\n",
    "\n",
    "if not os.path.exists(agdir):\n",
    "    logger.info(\"ERROR: Cannot proceed without a valid notebook directory path\")\n",
    "else:    \n",
    "    logger.info('Found activegit at {0}'.format(agdir))\n",
    "    \n",
    "ag = activegit.ActiveGit(agdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read new (unlabeled) candidates and prepare unlabeled pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datalist = rflearn.elastic.indextodatalist(unlabeled=True)\n",
    "obslist, loc, prop = rflearn.elastic.restorecands(datalist)\n",
    "stat_features = rflearn.features.stat_features(prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active learning loop\n",
    "\n",
    "#### Take least certain predictions and ask expert to classify. Result is then fed back in to classifier to improve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up train, test and unlabeled pools\n",
    "clf = ag.classifier\n",
    "train_pool, train_targets = ag.training_data\n",
    "test_pool, test_targets = ag.testing_data\n",
    "unlabeled_pool_stat = stat_features\n",
    "\n",
    "# set up batches\n",
    "nunlabeled = len(obslist)\n",
    "cands_unlabeled_pool = np.array(range(nunlabeled))\n",
    "subset_threshold = 75\n",
    "subset_perc = 0.666\n",
    "n_jobs = 1\n",
    "vers = [int(version.lstrip('stat')) for version in ag.versions if 'stat' in version]\n",
    "batch_size=2\n",
    "bi = 0 # batch index\n",
    "\n",
    "nbatches = nunlabeled/batch_size\n",
    "acc = np.zeros((nbatches, 1)) - 1\n",
    "fnr = np.zeros((nbatches, 1)) - 1\n",
    "fpr = np.zeros((nbatches, 1)) - 1\n",
    "\n",
    "logger.info(\"TRAIN POOL SIZE: {0}\".format(len(train_pool)))\n",
    "logger.info(\"TRAIN TARGETS SIZE: {0}\".format(len(train_targets)))\n",
    "logger.info(\"UNLABELED POOL SIZE: {0}\".format(unlabeled_pool_stat.shape))\n",
    "logger.info(\"NUNLABELED: {0}\".format(nunlabeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# START ACTIVE LEARNING LOOP\n",
    "# \n",
    "while (nunlabeled > 0): # while still examples in unlabeled pool\n",
    "    \n",
    "    # get performance stats for classifier on validation set\n",
    "    test_preds = clf.predict(test_pool)    \n",
    "    acc[bi], fpr[bi], fnr[bi] = rflearn.features.calc_acc_fpr_fnr(test_targets, test_preds)\n",
    "    print \"BATCH %d acc, fpr, fnr: (%.3f, %.3f, %.3f)\" % (bi, acc[bi], fpr[bi], fnr[bi])\n",
    "        \n",
    "    # choose a subset of the unlabeled pool to classify\n",
    "    subset_size = int(np.floor(subset_perc * nunlabeled)) if (nunlabeled > subset_threshold) else nunlabeled\n",
    "    cands_rand_subset = np.random.choice(cands_unlabeled_pool, subset_size, replace=False)\n",
    "    subset_pool = unlabeled_pool_stat[cands_rand_subset,:]\n",
    "        \n",
    "    # classify that subset\n",
    "    subset_pool_probs = clf.predict_proba(subset_pool) \n",
    "    \n",
    "    # choose the most uncertain bunch to present to the user\n",
    "    batch_subset_indices = (np.argsort(abs(subset_pool_probs[:,0] - subset_pool_probs[:,1])))[0:batch_size]\n",
    "    batch_subset_probs = subset_pool_probs[batch_subset_indices,:]\n",
    "    \n",
    "    # ... finds the corresponding cands from the unlabeled pools\n",
    "    batch_cand_indices = cands_rand_subset[batch_subset_indices]\n",
    "    \n",
    "    # present cand_indices to the user\n",
    "    batch_cand_targets = []\n",
    "    modified_data = []\n",
    "    # move those examples into the training pool, remove them from the unlabeled pool\n",
    "    for ci in range(batch_size):\n",
    "        candi = batch_cand_indices[ci]\n",
    "        logger.info('SNR = {0}'.format(unlabeled_pool_stat[candi,0]))\n",
    "        logger.info(\"RDF Probs=({0},{1})\".format(batch_subset_probs[ci,0], batch_subset_probs[ci,1]) )\n",
    "        serveimage(datalist[candi]['candidate_png'])\n",
    "        \n",
    "        while 1:\n",
    "            label = int(raw_input(\"LABEL: Is this real? (0,1) \"))\n",
    "            if label not in [0,1]:\n",
    "                logger.warn(\"Please enter in 0 or 1 only\")\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        batch_cand_targets.append(label)\n",
    "        datalist[candi]['labeled'] = 1\n",
    "        modified_data.append(datalist[candi])\n",
    "\n",
    "    # update elastic search index to show that a batch has been classified\n",
    "    rflearn.elastic.pushdata(modified_data)\n",
    "    \n",
    "    # augment train_pool, train_targets\n",
    "    train_pool = np.vstack( (train_pool, unlabeled_pool_stat[batch_cand_indices,:]) )\n",
    "    train_targets = np.concatenate( (train_targets, batch_cand_targets) )\n",
    "    \n",
    "    # remove from unlabeled pool candidates\n",
    "    cands_unlabeled_pool = np.delete(cands_unlabeled_pool, batch_cand_indices, axis=0)\n",
    "    nunlabeled = cands_unlabeled_pool.shape[0]\n",
    "    bi += 1\n",
    "\n",
    "    logger.info(\"TRAIN POOL SIZE: {0}\".format(len(train_pool)))\n",
    "    logger.info(\"TRAIN TARGETS SIZE: {0}\".format(len(train_targets)))\n",
    "    logger.info(\"UNLABELED POOL SIZE: {0}\".format(cands_unlabeled_pool.shape))\n",
    "    logger.info(\"NUNLABELED: {0}\".format(nunlabeled))\n",
    "    \n",
    "    # re-train \n",
    "    logger.info(\"Retraining classifier...\")\n",
    "    clf = rflearn.sklearn_utils.train_random_forest(train_pool, train_targets, n_jobs=n_jobs, verbose=verbose, n_estimators=300)\n",
    "    \n",
    "    # ask to continue\n",
    "    value = raw_input(\"Continue? (y,n): \")\n",
    "    if value ==  'n':\n",
    "        logger.info(\"Saving train, targets, and classifier to next version name...\")\n",
    "        rbv = 'stat{0}'.format(max(vers)+bi)\n",
    "        ag.write_testing_data(test_pool, test_targets)\n",
    "        ag.write_training_data([tuple(tr) for tr in train_pool], train_targets)\n",
    "        ag.write_classifier(clf)\n",
    "        #ag.commit_version(rbv)        \n",
    "        break\n",
    "    else:\n",
    "        logger.info('Continuing training...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot out ACCURACY, FPR, FNR\n",
    "nbatches = bi\n",
    "\n",
    "pl.figure(figsize=(16,4))\n",
    "pl.title('Active Learning Results')\n",
    "batch_sizes = [ i*batch_size for i in range(nbatches) ]\n",
    "pl.subplot(1,3,1)\n",
    "pl.plot(batch_sizes, acc[:nbatches], 'r-')\n",
    "pl.xlabel('num labeled')\n",
    "pl.ylabel('accuracy')\n",
    "pl.title('Accuracy')\n",
    "pl.subplot(1,3,2)\n",
    "pl.plot(batch_sizes, fpr[:nbatches], 'g-')\n",
    "pl.title('False Positive Rate')\n",
    "pl.ylabel('fpr')\n",
    "pl.xlabel('num labeled')\n",
    "pl.xticks(batch_sizes)\n",
    "pl.subplot(1,3,3)\n",
    "pl.plot(batch_sizes, fnr[:nbatches], 'b-')\n",
    "pl.title('False Negative Rate')\n",
    "pl.ylabel('fnr')\n",
    "pl.xlabel('num labeled')\n",
    "\n",
    "pl.xticks(batch_sizes)\n",
    "pl.show()\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
